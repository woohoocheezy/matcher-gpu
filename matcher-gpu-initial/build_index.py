# build_index.py
import asyncpg
import numpy as np
import faiss
import os
from dotenv import load_dotenv
import asyncio
import time
from datetime import datetime

load_dotenv()

# --- .env ì„¤ì • ---
DB_CONFIG = { "user": os.getenv("DB_USER"), "password": os.getenv("DB_PASSWORD"), "host": os.getenv("DB_HOST"), "port": int(os.getenv("DB_PORT")), "database": os.getenv("DB_DATABASE"), }
ORG_GROUP_ID = os.getenv("ORG_GROUP_ID")
START_DATE_STR = os.getenv("START_DATE")
END_DATE_STR = os.getenv("END_DATE")
VECTOR_DIMENSION = 512
FAISS_DATA_DIR = "/app/faiss_data"
FAISS_INDEX_PATH = os.path.join(FAISS_DATA_DIR, "faiss_index.bin")
FAISS_IDS_PATH = os.path.join(FAISS_DATA_DIR, "faiss_ids.npy")

# --- ë©”ëª¨ë¦¬ ê´€ë¦¬ ë° ì„±ëŠ¥ì„ ìœ„í•œ ì„¤ì • ---
BATCH_SIZE = 50000
TRAIN_SAMPLE_SIZE = 500000

async def main():
    if not all([ORG_GROUP_ID, START_DATE_STR, END_DATE_STR]):
        print("ì˜¤ë¥˜: .env íŒŒì¼ì— ORG_GROUP_ID, START_DATE, END_DATEê°€ ëª¨ë‘ ì„¤ì •ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
        return
    try:
        start_date = datetime.strptime(START_DATE_STR, "%Y-%m-%d %H:%M:%S")
        end_date = datetime.strptime(END_DATE_STR, "%Y-%m-%d %H:%M:%S")
    except ValueError as e:
        print(f"ì˜¤ë¥˜: ë‚ ì§œ í˜•ì‹ ì˜¤ë¥˜ - {e}")
        return

    print(f"--- ì¸ë±ìŠ¤ ë¹Œë“œ ì‹œì‘ (ëŒ€ìš©ëŸ‰ ì••ì¶• ëª¨ë“œ, ê¸°ê°„: {start_date} ~ {end_date}) ---")
    if not os.path.exists(FAISS_DATA_DIR): os.makedirs(FAISS_DATA_DIR)
    
    conn = await asyncpg.connect(**DB_CONFIG)
    
    # 1. [í›ˆë ¨]
    print(f"1. í›ˆë ¨ìš© ë°ì´í„° ìƒ˜í”Œ ê°€ì ¸ì˜¤ëŠ” ì¤‘ (ìµœëŒ€ {TRAIN_SAMPLE_SIZE}ê°œ)...")
    train_start_time = time.time()
    train_query = f'''
        SELECT face_descriptor FROM "{ORG_GROUP_ID}"."events" TABLESAMPLE SYSTEM (5)
        WHERE face_descriptor IS NOT NULL AND LENGTH(face_descriptor) = {VECTOR_DIMENSION} AND created_at >= $1 AND created_at < $2
        LIMIT {TRAIN_SAMPLE_SIZE};
    '''
    train_records = await conn.fetch(train_query, start_date, end_date)
    
    if len(train_records) < 256:
        print("í›ˆë ¨ìš© ë°ì´í„° ìƒ˜í”Œì´ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤."); await conn.close(); return

    print(f"  -> í›ˆë ¨ìš© ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ ({len(train_records)}ê°œ, ì†Œìš” ì‹œê°„: {time.time() - train_start_time:.2f}ì´ˆ)")

    print(f"2. Faiss ì¸ë±ìŠ¤ í›ˆë ¨ ì¤‘ (CPU)...")
    train_start_time = time.time()
    train_vectors = np.array([np.frombuffer(r['face_descriptor'], dtype=np.uint8) for r in train_records]).astype('float32')
    
    # ğŸ‘ˆ [ìˆ˜ì • ì™„ë£Œ] m ê°’ì„ 64ì—ì„œ 32ë¡œ ì¤„ì—¬ GPU ì•„í‚¤í…ì²˜ í•œê³„ì— ë§ì¶¤
    nlist = min(16384, int(np.sqrt(len(train_records)) * 8))
    m = 32  # ë²¡í„°ë¥¼ 32ê°œ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ ì„œ ì••ì¶•
    bits = 8
    
    quantizer = faiss.IndexFlatL2(VECTOR_DIMENSION)
    cpu_index = faiss.IndexIVFPQ(quantizer, VECTOR_DIMENSION, nlist, m, bits)
    
    cpu_index.train(train_vectors)
    del train_records, train_vectors
    print(f"  -> CPU ì¸ë±ìŠ¤ í›ˆë ¨ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {time.time() - train_start_time:.2f}ì´ˆ)")

    # 3. [ì¶”ê°€]
    print("3. ì „ì²´ ë°ì´í„°ë¥¼ ë°°ì¹˜ ë‹¨ìœ„ë¡œ GPU ì¸ë±ìŠ¤ì— ì¶”ê°€í•˜ëŠ” ì¤‘...")
    add_start_time = time.time()
    
    res = faiss.StandardGpuResources()
    gpu_index = faiss.index_cpu_to_gpu(res, 0, cpu_index)
    
    all_db_ids = []
    batch_vectors = []
    total_vectors_added = 0
    
    main_query = f'SELECT id, face_descriptor FROM "{ORG_GROUP_ID}"."events" WHERE face_descriptor IS NOT NULL AND LENGTH(face_descriptor) = {VECTOR_DIMENSION} AND created_at >= $1 AND created_at < $2'
    
    async with conn.transaction():
        async for record in conn.cursor(main_query, start_date, end_date):
            all_db_ids.append(record['id'])
            batch_vectors.append(np.frombuffer(record['face_descriptor'], dtype=np.uint8))
            
            if len(batch_vectors) == BATCH_SIZE:
                gpu_index.add(np.array(batch_vectors).astype('float32'))
                total_vectors_added += len(batch_vectors)
                print(f"  ... {total_vectors_added}ê°œ ë²¡í„° ì¶”ê°€ë¨ (ì§„í–‰ ì‹œê°„: {time.time() - add_start_time:.2f}ì´ˆ)")
                batch_vectors = []

    if batch_vectors:
        gpu_index.add(np.array(batch_vectors).astype('float32'))
        total_vectors_added += len(batch_vectors)
        print(f"  ... {total_vectors_added}ê°œ ë²¡í„° ì¶”ê°€ë¨ (ì§„í–‰ ì‹œê°„: {time.time() - add_start_time:.2f}ì´ˆ)")

    await conn.close()
    print(f"  -> ì „ì²´ ë°ì´í„° ì¶”ê°€ ì™„ë£Œ ({total_vectors_added}ê°œ, ì´ ì†Œìš” ì‹œê°„: {time.time() - add_start_time:.2f}ì´ˆ)")

    # 4. [ì €ì¥]
    print("4. ì¸ë±ìŠ¤ íŒŒì¼ ì €ì¥ ì¤‘...")
    save_start_time = time.time()
    cpu_index_to_save = faiss.index_gpu_to_cpu(gpu_index)
    faiss.write_index(cpu_index_to_save, FAISS_INDEX_PATH)
    np.save(FAISS_IDS_PATH, np.array(all_db_ids))
    print(f"  -> íŒŒì¼ ì €ì¥ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {time.time() - save_start_time:.2f}ì´ˆ)")
    print("--- ì¸ë±ìŠ¤ ë¹Œë“œ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ! ---")

if __name__ == "__main__":
    asyncio.run(main())
