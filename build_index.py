# build_index.py
import asyncpg
import numpy as np
import faiss
import os
from dotenv import load_dotenv
import asyncio
import time
from datetime import datetime  # ğŸ‘ˆ [ìˆ˜ì •] datetime ëª¨ë“ˆ ì¶”ê°€

load_dotenv()

# --- .env íŒŒì¼ì—ì„œ ëª¨ë“  ì„¤ì •ê°’ ì½ì–´ì˜¤ê¸° ---
DB_CONFIG = {
    "user": os.getenv("DB_USER"),
    "password": os.getenv("DB_PASSWORD"),
    "host": os.getenv("DB_HOST"),
    "port": int(os.getenv("DB_PORT")),
    "database": os.getenv("DB_DATABASE"),
}
ORG_GROUP_ID = os.getenv("ORG_GROUP_ID")
# .envì—ì„œ ë‚ ì§œ ë¬¸ìì—´ ì½ì–´ì˜¤ê¸°
START_DATE_STR = os.getenv("START_DATE")
END_DATE_STR = os.getenv("END_DATE")

# --- ì¤‘ìš” ì„¤ì • ---
VECTOR_DIMENSION = 512
FAISS_DATA_DIR = "/app/faiss_data"
FAISS_INDEX_PATH = os.path.join(FAISS_DATA_DIR, "faiss_index.bin")
FAISS_IDS_PATH = os.path.join(FAISS_DATA_DIR, "faiss_ids.npy")

# --- ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ìœ„í•œ ë°°ì¹˜ ì„¤ì • ---
BATCH_SIZE = 100000
TRAIN_SAMPLE_SIZE = 1000000


async def main():
    # --- ì„¤ì •ê°’ ìœ íš¨ì„± ê²€ì‚¬ ---
    if not all([ORG_GROUP_ID, START_DATE_STR, END_DATE_STR]):
        print(
            "ì˜¤ë¥˜: .env íŒŒì¼ì— ORG_GROUP_ID, START_DATE, END_DATEê°€ ëª¨ë‘ ì„¤ì •ë˜ì–´ì•¼ í•©ë‹ˆë‹¤."
        )
        return

    # ğŸ‘ˆ [ìˆ˜ì • ì™„ë£Œ] ë¬¸ìì—´ì„ datetime ê°ì²´ë¡œ ë³€í™˜
    try:
        start_date = datetime.strptime(START_DATE_STR, "%Y-%m-%d %H:%M:%S")
        end_date = datetime.strptime(END_DATE_STR, "%Y-%m-%d %H:%M:%S")
    except ValueError:
        print("ì˜¤ë¥˜: .envì˜ ë‚ ì§œ í˜•ì‹ì´ 'YYYY-MM-DD HH:MI:SS'ì™€ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    print(f"--- ì¸ë±ìŠ¤ ë¹Œë“œ ì‹œì‘ (ê¸°ê°„: {start_date} ~ {end_date}) ---")

    if not os.path.exists(FAISS_DATA_DIR):
        os.makedirs(FAISS_DATA_DIR)

    print("Connecting to DB...")
    conn = await asyncpg.connect(**DB_CONFIG)

    # 1. [í›ˆë ¨] ì§€ì •ëœ ê¸°ê°„ ë‚´ ë°ì´í„°ì˜ ì¼ë¶€ë§Œ ê°€ì ¸ì™€ ì¸ë±ìŠ¤ í›ˆë ¨
    print(f"1. í›ˆë ¨ìš© ë°ì´í„° ìƒ˜í”Œ ê°€ì ¸ì˜¤ëŠ” ì¤‘ (ìµœëŒ€ {TRAIN_SAMPLE_SIZE}ê°œ)...")
    train_start_time = time.time()

    train_query = f"""
        SELECT face_descriptor FROM "{ORG_GROUP_ID}"."events"
        WHERE 
            face_descriptor IS NOT NULL AND 
            LENGTH(face_descriptor) = {VECTOR_DIMENSION} AND
            created_at >= $1 AND created_at < $2
        ORDER BY RANDOM() 
        LIMIT {TRAIN_SAMPLE_SIZE};
    """
    # ğŸ‘ˆ [ìˆ˜ì • ì™„ë£Œ] ë³€í™˜ëœ datetime ê°ì²´ë¥¼ ì¿¼ë¦¬ì— ì „ë‹¬
    train_records = await conn.fetch(train_query, start_date, end_date)
    print(
        f"  -> í›ˆë ¨ìš© ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ ({len(train_records)}ê°œ, ì†Œìš” ì‹œê°„: {time.time() - train_start_time:.2f}ì´ˆ)"
    )

    if len(train_records) < 1000:
        print("í›ˆë ¨ìš© ë°ì´í„° ìƒ˜í”Œì´ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        await conn.close()
        return

    print(f"2. Faiss ì¸ë±ìŠ¤ í›ˆë ¨ ì¤‘...")
    train_start_time = time.time()
    train_vectors = np.array(
        [np.frombuffer(r["face_descriptor"], dtype=np.uint8) for r in train_records]
    ).astype("float32")

    res = faiss.StandardGpuResources()
    nlist = int(np.sqrt(len(train_records)) * 4)
    quantizer = faiss.IndexFlatL2(VECTOR_DIMENSION)
    gpu_index = faiss.GpuIndexIVFFlat(res, VECTOR_DIMENSION, nlist, faiss.METRIC_L2)
    gpu_index.train(train_vectors)
    del train_vectors
    print(f"  -> ì¸ë±ìŠ¤ í›ˆë ¨ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {time.time() - train_start_time:.2f}ì´ˆ)")

    # 2. [ì¶”ê°€] ì§€ì •ëœ ê¸°ê°„ì˜ ì „ì²´ ë°ì´í„°ë¥¼ ì»¤ì„œ(Cursor)ë¥¼ ì‚¬ìš©í•´ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
    print("3. ì „ì²´ ë°ì´í„°ë¥¼ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì¸ë±ìŠ¤ì— ì¶”ê°€í•˜ëŠ” ì¤‘...")
    add_start_time = time.time()
    all_db_ids = []
    total_vectors_added = 0

    main_query = f'SELECT id, face_descriptor FROM "{ORG_GROUP_ID}"."events" WHERE face_descriptor IS NOT NULL AND created_at >= $1 AND created_at < $2'

    async with conn.transaction():
        # ğŸ‘ˆ [ìˆ˜ì • ì™„ë£Œ] ë³€í™˜ëœ datetime ê°ì²´ë¥¼ ì¿¼ë¦¬ì— ì „ë‹¬
        async for record in conn.cursor(main_query, start_date, end_date):
            if len(record["face_descriptor"]) == VECTOR_DIMENSION:
                all_db_ids.append(record["id"])
                vector = (
                    np.frombuffer(record["face_descriptor"], dtype=np.uint8)
                    .astype("float32")
                    .reshape(1, -1)
                )
                gpu_index.add(vector)
                total_vectors_added += 1
                if total_vectors_added % BATCH_SIZE == 0:
                    print(
                        f"  ... {total_vectors_added}ê°œ ë²¡í„° ì¶”ê°€ë¨ (ì§„í–‰ ì‹œê°„: {time.time() - add_start_time:.2f}ì´ˆ)"
                    )

    await conn.close()
    print(
        f"  -> ì „ì²´ ë°ì´í„° ì¶”ê°€ ì™„ë£Œ ({total_vectors_added}ê°œ, ì´ ì†Œìš” ì‹œê°„: {time.time() - add_start_time:.2f}ì´ˆ)"
    )

    # 3. [ì €ì¥] ì™„ì„±ëœ ì¸ë±ìŠ¤ì™€ ID ë§µ ì €ì¥
    print("4. ì¸ë±ìŠ¤ íŒŒì¼ ì €ì¥ ì¤‘...")
    save_start_time = time.time()
    cpu_index = faiss.index_gpu_to_cpu(gpu_index)
    faiss.write_index(cpu_index, FAISS_INDEX_PATH)
    np.save(FAISS_IDS_PATH, np.array(all_db_ids))
    print(f"  -> íŒŒì¼ ì €ì¥ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {time.time() - save_start_time:.2f}ì´ˆ)")
    print("--- ì¸ë±ìŠ¤ ë¹Œë“œ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ! ---")


if __name__ == "__main__":
    asyncio.run(main())
